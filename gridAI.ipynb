{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "execution_state": "idle",
   "id": "cd1448df-c8f4-46ee-b50b-9333a108c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import boto3\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pyathena import connect\n",
    "import sagemaker\n",
    "from sqlalchemy.engine import create_engine\n",
    "import warnings\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import image_uris\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee222c-72be-4a58-8d74-f971302155f2",
   "metadata": {},
   "source": [
    "## Check s3 for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_state": "idle",
   "id": "f4cf23c6-54ea-41e1-b935-01068bd383bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eia_electricity/eia_data_demand_20250324_225715.json\n",
      "eia_electricity/eia_data_demand_20250325_021240.json\n",
      "eia_electricity/eia_data_energy_source_20250323_200432.json\n",
      "eia_electricity/eia_data_neighboring_bal_20250324_224805.json\n",
      "eia_electricity/eia_data_subregion_20250323_191441.json\n",
      "eia_electricity/eia_data_subregion_20250325_021741.json\n"
     ]
    }
   ],
   "source": [
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# List objects with the prefix\n",
    "response = s3.list_objects_v2(Bucket='ecogridaidata', Prefix='eia_electricity/eia_data')\n",
    "\n",
    "# Print the file keys\n",
    "for obj in response.get('Contents', []):\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c2468-f4ba-4dcc-ab34-c3979b1336bb",
   "metadata": {},
   "source": [
    "Note: If data is not available, locate \"RTC:ADS508TeamProject/installation/Installation & Set-Up.ipynb\" notebook to run refesh data from the EIA website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075da31d-8842-4e60-9039-4ac2ecc25889",
   "metadata": {},
   "source": [
    "## Load data stored as a json file in s3 \"ecogridaidata\" into a dataframe for verification and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_state": "idle",
   "id": "c189a744-2c38-4657-92d7-8abed112937e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>subba</th>\n",
       "      <th>subba-name</th>\n",
       "      <th>parent</th>\n",
       "      <th>parent-name</th>\n",
       "      <th>timezone</th>\n",
       "      <th>value</th>\n",
       "      <th>value-units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>247213</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Central</td>\n",
       "      <td>247876</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>248481</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>247213</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>246697</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period subba                subba-name parent  \\\n",
       "0  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "1  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "2  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "3  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "4  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "\n",
       "                              parent-name  timezone   value    value-units  \n",
       "0  California Independent System Operator   Arizona  247213  megawatthours  \n",
       "1  California Independent System Operator   Central  247876  megawatthours  \n",
       "2  California Independent System Operator   Eastern  248481  megawatthours  \n",
       "3  California Independent System Operator  Mountain  247213  megawatthours  \n",
       "4  California Independent System Operator   Pacific  246697  megawatthours  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S3 path to your file\n",
    "s3_uri = \"s3://ecogridaidata/eia_electricity/eia_data_subregion_20250323_191441.json\"\n",
    "s3_uri2 = \"s3://ecogridaidata/eia_electricity/eia_data_energy_source_20250323_200432.json\"\n",
    "s3_uri3 = \"s3://ecogridaidata/eia_electricity/eia_data_neighboring_bal_20250324_224805.json\"\n",
    "s3_uri4 = \"s3://ecogridaidata/eia_electricity/eia_data_demand_20250325_021240.json\"\n",
    "\n",
    "# Read json directly into pandas DataFrame\n",
    "df_subregion = pd.read_json(s3_uri, storage_options={\"anon\": False})\n",
    "df_energysource = pd.read_json(s3_uri2, storage_options={\"anon\": False})\n",
    "df_neighbor_bal = pd.read_json(s3_uri3, storage_options={\"anon\": False})\n",
    "df_demand = pd.read_json(s3_uri4, storage_options={\"anon\": False})\n",
    "\n",
    "# Preview the data\n",
    "df_subregion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_state": "idle",
   "id": "9bf7a16d-1e42-4376-9eec-34598d6dfdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>respondent</th>\n",
       "      <th>respondent-name</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>type-name</th>\n",
       "      <th>timezone</th>\n",
       "      <th>timezone-description</th>\n",
       "      <th>value</th>\n",
       "      <th>value-units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>COL</td>\n",
       "      <td>Coal</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>23782</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>COL</td>\n",
       "      <td>Coal</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central</td>\n",
       "      <td>23309</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>COL</td>\n",
       "      <td>Coal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>22893</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>COL</td>\n",
       "      <td>Coal</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>23782</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>COL</td>\n",
       "      <td>Coal</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>24422</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period respondent                        respondent-name fueltype  \\\n",
       "0  2024-12-31       AECI  Associated Electric Cooperative, Inc.      COL   \n",
       "1  2024-12-31       AECI  Associated Electric Cooperative, Inc.      COL   \n",
       "2  2024-12-31       AECI  Associated Electric Cooperative, Inc.      COL   \n",
       "3  2024-12-31       AECI  Associated Electric Cooperative, Inc.      COL   \n",
       "4  2024-12-31       AECI  Associated Electric Cooperative, Inc.      COL   \n",
       "\n",
       "  type-name  timezone timezone-description  value    value-units  \n",
       "0      Coal   Arizona              Arizona  23782  megawatthours  \n",
       "1      Coal   Central              Central  23309  megawatthours  \n",
       "2      Coal   Eastern              Eastern  22893  megawatthours  \n",
       "3      Coal  Mountain             Mountain  23782  megawatthours  \n",
       "4      Coal   Pacific              Pacific  24422  megawatthours  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_energysource.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_state": "idle",
   "id": "e0aeba84-4cb8-4453-8ddb-b20021e47e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>fromba</th>\n",
       "      <th>fromba-name</th>\n",
       "      <th>toba</th>\n",
       "      <th>toba-name</th>\n",
       "      <th>timezone</th>\n",
       "      <th>value</th>\n",
       "      <th>value-units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Midcontinent Independent System Operator, Inc.</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>584</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Midcontinent Independent System Operator, Inc.</td>\n",
       "      <td>Central</td>\n",
       "      <td>359</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Midcontinent Independent System Operator, Inc.</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>321</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Midcontinent Independent System Operator, Inc.</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>584</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Midcontinent Independent System Operator, Inc.</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1111</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period fromba                            fromba-name  toba  \\\n",
       "0  2024-12-31   AECI  Associated Electric Cooperative, Inc.  MISO   \n",
       "1  2024-12-31   AECI  Associated Electric Cooperative, Inc.  MISO   \n",
       "2  2024-12-31   AECI  Associated Electric Cooperative, Inc.  MISO   \n",
       "3  2024-12-31   AECI  Associated Electric Cooperative, Inc.  MISO   \n",
       "4  2024-12-31   AECI  Associated Electric Cooperative, Inc.  MISO   \n",
       "\n",
       "                                        toba-name  timezone  value  \\\n",
       "0  Midcontinent Independent System Operator, Inc.   Arizona    584   \n",
       "1  Midcontinent Independent System Operator, Inc.   Central    359   \n",
       "2  Midcontinent Independent System Operator, Inc.   Eastern    321   \n",
       "3  Midcontinent Independent System Operator, Inc.  Mountain    584   \n",
       "4  Midcontinent Independent System Operator, Inc.   Pacific   1111   \n",
       "\n",
       "     value-units  \n",
       "0  megawatthours  \n",
       "1  megawatthours  \n",
       "2  megawatthours  \n",
       "3  megawatthours  \n",
       "4  megawatthours  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neighbor_bal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "execution_state": "idle",
   "id": "587df709-5242-4e81-baba-1ce4edc486c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>respondent</th>\n",
       "      <th>respondent-name</th>\n",
       "      <th>type</th>\n",
       "      <th>type-name</th>\n",
       "      <th>timezone</th>\n",
       "      <th>timezone-description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-24</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>DF</td>\n",
       "      <td>Day-ahead demand forecast</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-24</td>\n",
       "      <td>AECI</td>\n",
       "      <td>Associated Electric Cooperative, Inc.</td>\n",
       "      <td>DF</td>\n",
       "      <td>Day-ahead demand forecast</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-24</td>\n",
       "      <td>AVA</td>\n",
       "      <td>Avista Corporation</td>\n",
       "      <td>DF</td>\n",
       "      <td>Day-ahead demand forecast</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-24</td>\n",
       "      <td>AVA</td>\n",
       "      <td>Avista Corporation</td>\n",
       "      <td>DF</td>\n",
       "      <td>Day-ahead demand forecast</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-24</td>\n",
       "      <td>AVA</td>\n",
       "      <td>Avista Corporation</td>\n",
       "      <td>DF</td>\n",
       "      <td>Day-ahead demand forecast</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period respondent                        respondent-name type  \\\n",
       "0  2025-03-24       AECI  Associated Electric Cooperative, Inc.   DF   \n",
       "1  2025-03-24       AECI  Associated Electric Cooperative, Inc.   DF   \n",
       "2  2025-03-24        AVA                     Avista Corporation   DF   \n",
       "3  2025-03-24        AVA                     Avista Corporation   DF   \n",
       "4  2025-03-24        AVA                     Avista Corporation   DF   \n",
       "\n",
       "                   type-name timezone timezone-description  \n",
       "0  Day-ahead demand forecast  Central              Central  \n",
       "1  Day-ahead demand forecast  Eastern              Eastern  \n",
       "2  Day-ahead demand forecast  Arizona              Arizona  \n",
       "3  Day-ahead demand forecast  Central              Central  \n",
       "4  Day-ahead demand forecast  Eastern              Eastern  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69136711-6330-4daf-a277-1161421cdf4d",
   "metadata": {},
   "source": [
    "## Create Athena Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "execution_state": "idle",
   "id": "325ee3f1-e0b8-4d6c-93b9-0f204457d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for Athena readability\n",
    "df_subregion.to_csv(\"s3://ecogridaidata/eia_electricity/subregion.csv\", index=False)\n",
    "df_energysource.to_csv(\"s3://ecogridaidata/eia_electricity/data_csv/energysource.csv\", index=False)\n",
    "df_neighbor_bal.to_csv(\"s3://ecogridaidata/eia_electricity/data_csv/neighboring_bal.csv\", index=False)\n",
    "df_demand.to_csv(\"s3://ecogridaidata/eia_electricity/demand.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "execution_state": "idle",
   "id": "ec0c52e1-ccca-4d03-847d-3f19020e16ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyathena.cursor.Cursor at 0x7f2fb6619b10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup\n",
    "sess = sagemaker.Session()\n",
    "bucket = 'ecogridaidata'\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "s3_staging_dir = f\"s3://{bucket}/athena/staging\"\n",
    "database_name = \"ecodataaidatabase\"\n",
    "\n",
    "# Connect\n",
    "conn = connect(region_name=region, s3_staging_dir=s3_staging_dir)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create DB if needed\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS ecodataaidatabase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "execution_state": "idle",
   "id": "e6ace94b-1272-441a-9e3e-88eacf0898d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyathena.cursor.Cursor at 0x7f2fb213da10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subregion Table\n",
    "query = f\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS {database_name}.subregion (\n",
    "    period string,\n",
    "    subba string,\n",
    "    `subba-name` string,\n",
    "    parent string,\n",
    "    `parent-name` string,\n",
    "    timezone string,\n",
    "    value int,\n",
    "    `value-units` string\n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES (\n",
    "  \"separatorChar\" = \",\",\n",
    "  \"quoteChar\" = \"\\\\\"\"\n",
    ")\n",
    "LOCATION 's3://{bucket}/athena/subregion/'\n",
    "TBLPROPERTIES ('skip.header.line.count'='1');\n",
    "\"\"\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "execution_state": "idle",
   "id": "3e327dc3-5b29-4fee-a670-1aaa94b6ff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1706/2186447736.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>subba</th>\n",
       "      <th>subba-name</th>\n",
       "      <th>parent</th>\n",
       "      <th>parent-name</th>\n",
       "      <th>timezone</th>\n",
       "      <th>value</th>\n",
       "      <th>value-units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>247213</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Central</td>\n",
       "      <td>247876</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>248481</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>247213</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>CISO</td>\n",
       "      <td>California Independent System Operator</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>246697</td>\n",
       "      <td>megawatthours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period subba                subba-name parent  \\\n",
       "0  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "1  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "2  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "3  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "4  2024-12-31  PGAE  Pacific Gas and Electric   CISO   \n",
       "\n",
       "                              parent-name  timezone   value    value-units  \n",
       "0  California Independent System Operator   Arizona  247213  megawatthours  \n",
       "1  California Independent System Operator   Central  247876  megawatthours  \n",
       "2  California Independent System Operator   Eastern  248481  megawatthours  \n",
       "3  California Independent System Operator  Mountain  247213  megawatthours  \n",
       "4  California Independent System Operator   Pacific  246697  megawatthours  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Query Subregion\n",
    "query = f\"SELECT * FROM {database_name}.subregion LIMIT 10;\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_state": "idle",
   "id": "5332721b-28fc-4714-be53-d3a702fac541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyathena.cursor.Cursor at 0x7f2fb0a5ec90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Energy Source Table\n",
    "query = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS ecodataaidatabase.energysource (\n",
    "    period string,\n",
    "    respondent string,\n",
    "    `respondent-name` string,\n",
    "    fueltype string,\n",
    "    `type-name` string,\n",
    "    timezone string,\n",
    "    `timezone-description` string,\n",
    "    value int,\n",
    "    `value-units` string\n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES (\n",
    "  \"separatorChar\" = \",\",\n",
    "  \"quoteChar\" = \"\\\\\"\"\n",
    ")\n",
    "LOCATION 's3://ecogridaidata/athena/energysource/'\n",
    "TBLPROPERTIES ('skip.header.line.count'='1');\n",
    "\"\"\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_state": "idle",
   "id": "338ebd0d-7911-4a73-8769-dcf77dc964a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyathena.cursor.Cursor at 0x7f2fb08cdcd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neighboring Table\n",
    "query = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS ecodataaidatabase.neighboring_bal (\n",
    "    period string,\n",
    "    fromba string,\n",
    "    `fromba-name` string,\n",
    "    toba string,\n",
    "    `toba-name` string,\n",
    "    timezone string,\n",
    "    value int,\n",
    "    `value-units` string\n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES (\n",
    "  \"separatorChar\" = \",\",\n",
    "  \"quoteChar\" = \"\\\\\"\"\n",
    ")\n",
    "LOCATION 's3://ecogridaidata/athena/neighboring_bal/'\n",
    "TBLPROPERTIES ('skip.header.line.count'='1');\n",
    "\"\"\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_state": "idle",
   "id": "2358cbef-8f78-4a49-beed-14807ace3f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyathena.cursor.Cursor at 0x7f7a37355b50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demand Table\n",
    "query = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS ecodataaidatabase.demand (\n",
    "    period string,\n",
    "    respondent string,\n",
    "    `respondent-name` string,\n",
    "    type string,\n",
    "    `type-name` string,\n",
    "    timezone string,\n",
    "    `timezone-description` string,\n",
    "    value int,\n",
    "    `value-units` string\n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES (\n",
    "  \"separatorChar\" = \",\",\n",
    "  \"quoteChar\" = \"\\\\\"\"\n",
    ")\n",
    "LOCATION 's3://ecogridaidata/athena/demand/'\n",
    "TBLPROPERTIES ('skip.header.line.count'='1');\n",
    "\"\"\"\n",
    "# Run the query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_state": "idle",
   "id": "176fa193-fb7c-4f3c-8521-6c14fd685cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/300048193.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_tables = pd.read_sql(f\"SHOW TABLES IN {database_name}\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tab_name\n",
      "0           demand\n",
      "1     energysource\n",
      "2  neighboring_bal\n",
      "3        subregion\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "df_tables = pd.read_sql(f\"SHOW TABLES IN {database_name}\", conn)\n",
    "print(df_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_state": "idle",
   "id": "f7818e1c-44ff-48ef-ac96-2ec43a13c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "if database_name in df_tables.values:\n",
    "    ingest_create_athena_db_passed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b08de9-839c-4d2c-8b53-7e111309cb0b",
   "metadata": {},
   "source": [
    "## Exploratory Daya Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_state": "idle",
   "id": "8e3f8857-7937-4d35-b660-c40ed9847056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Subregion Dataset ===\n",
      "Shape: (302719, 8)\n",
      "Null values:\n",
      " period         0\n",
      "subba          0\n",
      "subba-name     0\n",
      "parent         0\n",
      "parent-name    0\n",
      "timezone       0\n",
      "value          0\n",
      "value-units    0\n",
      "dtype: int64\n",
      "Data types:\n",
      " period         object\n",
      "subba          object\n",
      "subba-name     object\n",
      "parent         object\n",
      "parent-name    object\n",
      "timezone       object\n",
      "value           int64\n",
      "value-units    object\n",
      "dtype: object\n",
      "\n",
      "=== Energy Source Dataset ===\n",
      "Shape: (1425802, 9)\n",
      "Null values:\n",
      " period                  0\n",
      "respondent              0\n",
      "respondent-name         0\n",
      "fueltype                0\n",
      "type-name               0\n",
      "timezone                0\n",
      "timezone-description    0\n",
      "value                   0\n",
      "value-units             0\n",
      "dtype: int64\n",
      "Data types:\n",
      " period                  object\n",
      "respondent              object\n",
      "respondent-name         object\n",
      "fueltype                object\n",
      "type-name               object\n",
      "timezone                object\n",
      "timezone-description    object\n",
      "value                    int64\n",
      "value-units             object\n",
      "dtype: object\n",
      "\n",
      "=== Neighbor Balancing Dataset ===\n",
      "Shape: (1233232, 8)\n",
      "Null values:\n",
      " period         0\n",
      "fromba         0\n",
      "fromba-name    0\n",
      "toba           0\n",
      "toba-name      0\n",
      "timezone       0\n",
      "value          0\n",
      "value-units    0\n",
      "dtype: int64\n",
      "Data types:\n",
      " period         object\n",
      "fromba         object\n",
      "fromba-name    object\n",
      "toba           object\n",
      "toba-name      object\n",
      "timezone       object\n",
      "value           int64\n",
      "value-units    object\n",
      "dtype: object\n",
      "\n",
      "=== Demand Dataset ===\n",
      "Shape: (1038828, 7)\n",
      "Null values:\n",
      " period                  0\n",
      "respondent              0\n",
      "respondent-name         0\n",
      "type                    0\n",
      "type-name               0\n",
      "timezone                0\n",
      "timezone-description    0\n",
      "dtype: int64\n",
      "Data types:\n",
      " period                  object\n",
      "respondent              object\n",
      "respondent-name         object\n",
      "type                    object\n",
      "type-name               object\n",
      "timezone                object\n",
      "timezone-description    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "for name, df in zip(\n",
    "    ['Subregion', 'Energy Source', 'Neighbor Balancing', 'Demand'],\n",
    "    [df_subregion, df_energysource, df_neighbor_bal, df_demand]\n",
    "):\n",
    "    print(f\"\\n=== {name} Dataset ===\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Null values:\\n\", df.isnull().sum())\n",
    "    print(\"Data types:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a6532b-78fe-4253-8e48-2fa1d8d552b4",
   "metadata": {},
   "source": [
    "Datasets do no contain any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "execution_state": "idle",
   "id": "5a9018e7-0b4e-434e-81e2-111ee3745460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subregion years in data: [2023, 2024]\n",
      "\n",
      "Energy Source years in data: [2023, 2024]\n",
      "\n",
      "Neighbor Balancing years in data: [2023, 2024]\n",
      "\n",
      "Demand years in data: [2025]\n"
     ]
    }
   ],
   "source": [
    "dfs = [df_subregion, df_energysource, df_neighbor_bal, df_demand]\n",
    "for df in dfs:\n",
    "    df['period'] = pd.to_datetime(df['period'])\n",
    "\n",
    "for name, df in zip(\n",
    "    ['Subregion', 'Energy Source', 'Neighbor Balancing', 'Demand'],\n",
    "    dfs\n",
    "):\n",
    "    years = df['period'].dt.year.unique()\n",
    "    print(f\"\\n{name} years in data:\", sorted(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "execution_state": "idle",
   "id": "d189930d-78bc-4d39-9359-eee2c9dd203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['period', 'respondent', 'respondent-name', 'type', 'type-name',\n",
      "       'timezone', 'timezone-description'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_demand.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb58335-956f-451d-adcc-4b359e732544",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "execution_state": "idle",
   "id": "13cdc599-ed37-48d1-9fab-8f5cc9bc3a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/4198048877.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_subregion = pd.read_sql(query_subregion, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subregion DataFrame after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>subba</th>\n",
       "      <th>parent</th>\n",
       "      <th>timezone</th>\n",
       "      <th>value</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>CISO</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>247213</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>CISO</td>\n",
       "      <td>Central</td>\n",
       "      <td>247876</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>CISO</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>248481</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>CISO</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>247213</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>CISO</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>246697</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      period subba parent  timezone   value  month  weekday\n",
       "0 2024-12-31  PGAE   CISO   Arizona  247213     12        1\n",
       "1 2024-12-31  PGAE   CISO   Central  247876     12        1\n",
       "2 2024-12-31  PGAE   CISO   Eastern  248481     12        1\n",
       "3 2024-12-31  PGAE   CISO  Mountain  247213     12        1\n",
       "4 2024-12-31  PGAE   CISO   Pacific  246697     12        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Subregion Dataset ---\n",
    "query_subregion = \"SELECT * FROM ecodataaidatabase.subregion\"\n",
    "df_subregion = pd.read_sql(query_subregion, conn)\n",
    "\n",
    "# Clean: drop unnecessary columns\n",
    "df_subregion.drop(columns=['subba-name', 'parent-name', 'value-units'], inplace=True)\n",
    "\n",
    "# Scrub: drop duplicates and rows missing critical fields\n",
    "df_subregion.drop_duplicates(inplace=True)\n",
    "df_subregion.dropna(subset=['period', 'value'], inplace=True)\n",
    "\n",
    "# Feature engineering: convert period to datetime and create new features\n",
    "df_subregion['period'] = pd.to_datetime(df_subregion['period'])\n",
    "df_subregion['month'] = df_subregion['period'].dt.month\n",
    "df_subregion['weekday'] = df_subregion['period'].dt.weekday\n",
    "\n",
    "# Preview\n",
    "print(\"Subregion DataFrame after cleaning:\")\n",
    "display(df_subregion.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "execution_state": "idle",
   "id": "f5aa20d0-3e85-45bb-b508-43c4e1d43f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/2554255695.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_energysource = pd.read_sql(query_energysource, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energysource DataFrame after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>respondent</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>timezone</th>\n",
       "      <th>value</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>SE</td>\n",
       "      <td>NG</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>442347</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>SE</td>\n",
       "      <td>NG</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>440939</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>SE</td>\n",
       "      <td>NG</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>439671</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>SE</td>\n",
       "      <td>NUC</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>168001</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>SE</td>\n",
       "      <td>NUC</td>\n",
       "      <td>Central</td>\n",
       "      <td>168034</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      period respondent fueltype  timezone   value  month  weekday\n",
       "0 2023-12-12         SE       NG   Eastern  442347     12        1\n",
       "1 2023-12-12         SE       NG  Mountain  440939     12        1\n",
       "2 2023-12-12         SE       NG   Pacific  439671     12        1\n",
       "3 2023-12-12         SE      NUC   Arizona  168001     12        1\n",
       "4 2023-12-12         SE      NUC   Central  168034     12        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Energysource Dataset ---\n",
    "query_energysource = \"SELECT * FROM ecodataaidatabase.energysource\"\n",
    "df_energysource = pd.read_sql(query_energysource, conn)\n",
    "\n",
    "# Clean: drop unnecessary columns\n",
    "df_energysource.drop(columns=['respondent-name', 'type-name', 'timezone-description', 'value-units'], inplace=True)\n",
    "\n",
    "# Scrub: drop duplicates and rows missing critical fields\n",
    "df_energysource.drop_duplicates(inplace=True)\n",
    "df_energysource.dropna(subset=['period', 'value', 'fueltype'], inplace=True)\n",
    "\n",
    "# Feature engineering: convert period to datetime and add time features\n",
    "df_energysource['period'] = pd.to_datetime(df_energysource['period'])\n",
    "df_energysource['month'] = df_energysource['period'].dt.month\n",
    "df_energysource['weekday'] = df_energysource['period'].dt.weekday\n",
    "\n",
    "# Preview\n",
    "print(\"Energysource DataFrame after cleaning:\")\n",
    "display(df_energysource.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "execution_state": "idle",
   "id": "d0e169a2-0e1b-468f-b2c3-79c702430cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/238914452.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_neighboring_bal = pd.read_sql(query_neighboring, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighboring Balancing DataFrame after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>fromba</th>\n",
       "      <th>toba</th>\n",
       "      <th>timezone</th>\n",
       "      <th>value</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>584</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Central</td>\n",
       "      <td>359</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>321</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>584</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>AECI</td>\n",
       "      <td>MISO</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1111</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      period fromba  toba  timezone  value  month  weekday\n",
       "0 2024-12-31   AECI  MISO   Arizona    584     12        1\n",
       "1 2024-12-31   AECI  MISO   Central    359     12        1\n",
       "2 2024-12-31   AECI  MISO   Eastern    321     12        1\n",
       "3 2024-12-31   AECI  MISO  Mountain    584     12        1\n",
       "4 2024-12-31   AECI  MISO   Pacific   1111     12        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Neighboring Balancing Dataset ---\n",
    "query_neighboring = \"SELECT * FROM ecodataaidatabase.neighboring_bal\"\n",
    "df_neighboring_bal = pd.read_sql(query_neighboring, conn)\n",
    "\n",
    "# Clean: drop unnecessary columns\n",
    "df_neighboring_bal.drop(columns=['fromba-name', 'toba-name', 'value-units'], inplace=True)\n",
    "\n",
    "# Scrub: drop duplicates and rows missing critical fields\n",
    "df_neighboring_bal.drop_duplicates(inplace=True)\n",
    "df_neighboring_bal.dropna(subset=['period', 'value', 'fromba', 'toba'], inplace=True)\n",
    "\n",
    "# Feature engineering: convert period to datetime and add new features\n",
    "df_neighboring_bal['period'] = pd.to_datetime(df_neighboring_bal['period'])\n",
    "df_neighboring_bal['month'] = df_neighboring_bal['period'].dt.month\n",
    "df_neighboring_bal['weekday'] = df_neighboring_bal['period'].dt.weekday\n",
    "\n",
    "# Preview\n",
    "print(\"Neighboring Balancing DataFrame after cleaning:\")\n",
    "display(df_neighboring_bal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "execution_state": "idle",
   "id": "3d6cdae3-8ad1-45b1-9efd-4787a4116ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/3728839611.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_demand = pd.read_sql(query_demand, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demand DataFrame after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>respondent</th>\n",
       "      <th>respondent-name</th>\n",
       "      <th>type</th>\n",
       "      <th>type-name</th>\n",
       "      <th>timezone</th>\n",
       "      <th>timezone-description</th>\n",
       "      <th>value</th>\n",
       "      <th>value-units</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [period, respondent, respondent-name, type, type-name, timezone, timezone-description, value, value-units, month, weekday]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Demand Dataset ---\n",
    "query_demand = \"SELECT * FROM ecodataaidatabase.demand\"\n",
    "df_demand = pd.read_sql(query_demand, conn)\n",
    "\n",
    "# Scrub: drop duplicates and rows missing critical fields\n",
    "df_demand.drop_duplicates(inplace=True)\n",
    "df_demand.dropna(subset=['period', 'value'], inplace=True)\n",
    "\n",
    "# Feature engineering: convert period to datetime and add new features\n",
    "df_demand['period'] = pd.to_datetime(df_demand['period'])\n",
    "df_demand['month'] = df_demand['period'].dt.month\n",
    "df_demand['weekday'] = df_demand['period'].dt.weekday\n",
    "\n",
    "# Preview\n",
    "print(\"Demand DataFrame after cleaning:\")\n",
    "display(df_demand.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "execution_state": "idle",
   "id": "005b793f-67ed-479d-8a4f-358d18a762bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/2974498777.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM ecodataaidatabase.demand LIMIT 10;\", conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>respondent</th>\n",
       "      <th>respondent-name</th>\n",
       "      <th>type</th>\n",
       "      <th>type-name</th>\n",
       "      <th>timezone</th>\n",
       "      <th>timezone-description</th>\n",
       "      <th>value</th>\n",
       "      <th>value-units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-23</td>\n",
       "      <td>SPA</td>\n",
       "      <td>Southwestern Power Administration</td>\n",
       "      <td>NG</td>\n",
       "      <td>Net generation</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-23</td>\n",
       "      <td>SPA</td>\n",
       "      <td>Southwestern Power Administration</td>\n",
       "      <td>NG</td>\n",
       "      <td>Net generation</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-23</td>\n",
       "      <td>SPA</td>\n",
       "      <td>Southwestern Power Administration</td>\n",
       "      <td>NG</td>\n",
       "      <td>Net generation</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-23</td>\n",
       "      <td>SPA</td>\n",
       "      <td>Southwestern Power Administration</td>\n",
       "      <td>TI</td>\n",
       "      <td>Total interchange</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-23</td>\n",
       "      <td>SPA</td>\n",
       "      <td>Southwestern Power Administration</td>\n",
       "      <td>TI</td>\n",
       "      <td>Total interchange</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period respondent                    respondent-name type  \\\n",
       "0  2025-03-23        SPA  Southwestern Power Administration   NG   \n",
       "1  2025-03-23        SPA  Southwestern Power Administration   NG   \n",
       "2  2025-03-23        SPA  Southwestern Power Administration   NG   \n",
       "3  2025-03-23        SPA  Southwestern Power Administration   TI   \n",
       "4  2025-03-23        SPA  Southwestern Power Administration   TI   \n",
       "\n",
       "           type-name  timezone timezone-description value value-units  \n",
       "0     Net generation   Eastern              Eastern  None        None  \n",
       "1     Net generation  Mountain             Mountain  None        None  \n",
       "2     Net generation   Pacific              Pacific  None        None  \n",
       "3  Total interchange   Central              Central  None        None  \n",
       "4  Total interchange   Eastern              Eastern  None        None  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Demand Query\n",
    "df = pd.read_sql(\"SELECT * FROM ecodataaidatabase.demand LIMIT 10;\", conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "execution_state": "idle",
   "id": "c20e3f7d-8b07-485c-8732-8cefbc0231bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/01/25 04:13:23] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Same images used for training and inference. Defaulting to image     <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         scope: inference.                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/01/25 04:13:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Same images used for training and inference. Defaulting to image     \u001b]8;id=745261;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=406788;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         scope: inference.                                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#530\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=646659;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=142287;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/1323569300.py:36: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  json_series = df.groupby('item_id').apply(format_series).tolist()\n"
     ]
    }
   ],
   "source": [
    "#prepare dataset for forecasting\n",
    "# Step 1: Setup\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = 'ecogridaidata'\n",
    "prefix = 'eia_electricity/cleaned'\n",
    "region = boto3.Session().region_name\n",
    "container = image_uris.retrieve(region=region, framework='forecasting-deepar')\n",
    "\n",
    "# Step 2: Preprocess dataset\n",
    "df = df_subregion.copy()\n",
    "\n",
    "# Format timestamp and item_id\n",
    "df['timestamp'] = pd.to_datetime(df['period'])\n",
    "df['item_id'] = df['subba'] + '_' + df['parent'] + '_' + df['timezone']\n",
    "df['target'] = df['value']\n",
    "\n",
    "# Select and reorder required columns\n",
    "df = df[['timestamp', 'item_id', 'target']]\n",
    "\n",
    "# Group each time series by item_id\n",
    "def format_series(group):\n",
    "    return {\n",
    "        \"start\": str(group['timestamp'].min()),\n",
    "        \"target\": group.sort_values('timestamp')['target'].tolist()\n",
    "    }\n",
    "\n",
    "json_series = df.groupby('item_id').apply(format_series).tolist()\n",
    "json_lines = '\\n'.join([str(obj).replace(\"'\", '\"') for obj in json_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "execution_state": "idle",
   "id": "f1b03564-fd93-421c-b77d-fd5c12cb6656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'JT6PTFRCX4ST6T0N',\n",
       "  'HostId': 'Gb+ri722wJVNUEqDoMaT80+Ja7L8Q1jOkvHCjslYlPGQI9cERap8m/Cwh8fBERj19/jAps0ZRfo=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'Gb+ri722wJVNUEqDoMaT80+Ja7L8Q1jOkvHCjslYlPGQI9cERap8m/Cwh8fBERj19/jAps0ZRfo=',\n",
       "   'x-amz-request-id': 'JT6PTFRCX4ST6T0N',\n",
       "   'date': 'Tue, 01 Apr 2025 04:13:33 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"aece5c3d02618e92e779e9be6e4050d8\"',\n",
       "   'x-amz-checksum-crc32': '7KtnGQ==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"aece5c3d02618e92e779e9be6e4050d8\"',\n",
       " 'ChecksumCRC32': '7KtnGQ==',\n",
       " 'ChecksumType': 'FULL_OBJECT',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save as csv and load to s3\n",
    "s3_key = f'{prefix}/train/train.json'\n",
    "s3_path = f's3://{bucket}/{s3_key}'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.put_object(Bucket=bucket, Key=s3_key, Body=json_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "execution_state": "idle",
   "id": "7b136bc6-3c71-47d0-a863-238ccbef44cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/01/25 04:21:59] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/01/25 04:21:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=555948;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=263189;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-01-04-21-59-288                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=111234;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=808764;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         forecasting-deepar-\u001b[1;36m2025\u001b[0m-04-01-04-21-59-288                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-01 04:21:59 Starting - Starting the training job...\n",
      "..25-04-01 04:22:21 Starting - Preparing the instances for training.\n",
      ".................01 Downloading - Downloading the training image.\n",
      "2025-04-01 04:25:43 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mRunning custom environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '30', 'early_stopping_patience': '10', 'epochs': '20', 'learning_rate': '0.001', 'likelihood': 'gaussian', 'mini_batch_size': '64', 'num_cells': '40', 'num_layers': '3', 'prediction_length': '14', 'time_freq': 'D'}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '10', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'gaussian', 'mini_batch_size': '64', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '3', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '30', 'epochs': '20', 'prediction_length': '14', 'time_freq': 'D'}\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] random_seed is None\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Integer time series\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] number of time series: 420\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] number of observations: 302719\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] mean target length: 720.7595238095238\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] min/mean/max target: 0.0/87875.29119084035/785360.0\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] mean abs(target): 87875.29119084035\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Small number of time series. Doing 2 passes over dataset with prob 0.7619047619047619 per epoch.\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/algorithm/core/date_feature_set.py:44: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  return index.weekofyear / 51.0 - 0.5\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] #memory_usage::<batchbuffer> = 7.95654296875 mb\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481555.2750628, \"EndTime\": 1743481555.3779666, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 101.85861587524414, \"count\": 1, \"min\": 101.85861587524414, \"max\": 101.85861587524414}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:55 INFO 140518249928512] #memory_usage::<model> = 28 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481555.3780472, \"EndTime\": 1743481555.5484116, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 273.2117176055908, \"count\": 1, \"min\": 273.2117176055908, \"max\": 273.2117176055908}}}\u001b[0m\n",
      "\u001b[34m[04:25:55] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 10240 bytes with malloc directly\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:56 INFO 140518249928512] Epoch[0] Batch[0] avg_epoch_loss=10.182460\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:56 INFO 140518249928512] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=10.182459831237793\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:56 INFO 140518249928512] Epoch[0] Batch[5] avg_epoch_loss=10.374042\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:56 INFO 140518249928512] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=10.37404203414917\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:56 INFO 140518249928512] Epoch[0] Batch [5]#011Speed: 405.46 samples/sec#011loss=10.374042\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:57 INFO 140518249928512] Epoch[0] Batch[10] avg_epoch_loss=10.254458\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:57 INFO 140518249928512] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=10.110957527160645\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:57 INFO 140518249928512] Epoch[0] Batch [10]#011Speed: 409.53 samples/sec#011loss=10.110958\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:57 INFO 140518249928512] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481555.5484726, \"EndTime\": 1743481557.5913832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"update.time\": {\"sum\": 2042.8330898284912, \"count\": 1, \"min\": 2042.8330898284912, \"max\": 2042.8330898284912}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:57 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=320.61720526909073 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:57 INFO 140518249928512] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:57 INFO 140518249928512] #quality_metric: host=algo-1, epoch=0, train loss <loss>=10.254458167336203\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:57 INFO 140518249928512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:57 INFO 140518249928512] Saved checkpoint to \"/opt/ml/model/state_3a321cc8-f4ff-444d-88de-0b1c0e6e633f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481557.5914524, \"EndTime\": 1743481557.6073666, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 15.409231185913086, \"count\": 1, \"min\": 15.409231185913086, \"max\": 15.409231185913086}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:58 INFO 140518249928512] Epoch[1] Batch[0] avg_epoch_loss=10.329785\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:58 INFO 140518249928512] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=10.329785346984863\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:59 INFO 140518249928512] Epoch[1] Batch[5] avg_epoch_loss=9.857443\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:59 INFO 140518249928512] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=9.8574431737264\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:25:59 INFO 140518249928512] Epoch[1] Batch [5]#011Speed: 277.25 samples/sec#011loss=9.857443\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:00 INFO 140518249928512] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481557.6074347, \"EndTime\": 1743481560.0247796, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2417.285442352295, \"count\": 1, \"min\": 2417.285442352295, \"max\": 2417.285442352295}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:00 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=262.68034880274735 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:00 INFO 140518249928512] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:00 INFO 140518249928512] #quality_metric: host=algo-1, epoch=1, train loss <loss>=9.941804122924804\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:00 INFO 140518249928512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:00 INFO 140518249928512] Saved checkpoint to \"/opt/ml/model/state_cc5d4bae-9595-437e-a32d-449ea0e1beaf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481560.0248485, \"EndTime\": 1743481560.0427139, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 17.330408096313477, \"count\": 1, \"min\": 17.330408096313477, \"max\": 17.330408096313477}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:00 INFO 140518249928512] Epoch[2] Batch[0] avg_epoch_loss=10.341583\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:00 INFO 140518249928512] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=10.341583251953125\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:01 INFO 140518249928512] Epoch[2] Batch[5] avg_epoch_loss=9.764976\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:01 INFO 140518249928512] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=9.764975547790527\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:01 INFO 140518249928512] Epoch[2] Batch [5]#011Speed: 391.79 samples/sec#011loss=9.764976\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] Epoch[2] Batch[10] avg_epoch_loss=9.702882\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=9.628369522094726\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] Epoch[2] Batch [10]#011Speed: 391.49 samples/sec#011loss=9.628370\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481560.042776, \"EndTime\": 1743481562.0305748, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1987.741470336914, \"count\": 1, \"min\": 1987.741470336914, \"max\": 1987.741470336914}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=325.98323181098385 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] #quality_metric: host=algo-1, epoch=2, train loss <loss>=9.702881899746982\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] Saved checkpoint to \"/opt/ml/model/state_9db9d473-a741-49f2-a8b0-6011ee7681ac-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481562.0306368, \"EndTime\": 1743481562.0472968, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 16.2811279296875, \"count\": 1, \"min\": 16.2811279296875, \"max\": 16.2811279296875}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] Epoch[3] Batch[0] avg_epoch_loss=10.122324\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:02 INFO 140518249928512] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=10.122323989868164\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:03 INFO 140518249928512] Epoch[3] Batch[5] avg_epoch_loss=9.949000\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:03 INFO 140518249928512] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=9.949000199635824\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:03 INFO 140518249928512] Epoch[3] Batch [5]#011Speed: 398.99 samples/sec#011loss=9.949000\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] Epoch[3] Batch[10] avg_epoch_loss=9.838983\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=9.706962966918946\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] Epoch[3] Batch [10]#011Speed: 402.86 samples/sec#011loss=9.706963\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481562.0473976, \"EndTime\": 1743481564.008259, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1960.8023166656494, \"count\": 1, \"min\": 1960.8023166656494, \"max\": 1960.8023166656494}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=345.7522734028914 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] #quality_metric: host=algo-1, epoch=3, train loss <loss>=9.838983275673606\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] Epoch[4] Batch[0] avg_epoch_loss=9.916338\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:04 INFO 140518249928512] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=9.916337966918945\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:05 INFO 140518249928512] Epoch[4] Batch[5] avg_epoch_loss=9.750372\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:05 INFO 140518249928512] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=9.750371615091959\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:05 INFO 140518249928512] Epoch[4] Batch [5]#011Speed: 400.24 samples/sec#011loss=9.750372\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:05 INFO 140518249928512] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481564.008369, \"EndTime\": 1743481565.7781553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1769.4745063781738, \"count\": 1, \"min\": 1769.4745063781738, \"max\": 1769.4745063781738}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:05 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=346.4117715217601 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:05 INFO 140518249928512] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:05 INFO 140518249928512] #quality_metric: host=algo-1, epoch=4, train loss <loss>=9.719394493103028\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:05 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:06 INFO 140518249928512] Epoch[5] Batch[0] avg_epoch_loss=9.719680\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:06 INFO 140518249928512] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=9.719679832458496\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:06 INFO 140518249928512] Epoch[5] Batch[5] avg_epoch_loss=9.686453\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:06 INFO 140518249928512] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=9.686452547709147\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:06 INFO 140518249928512] Epoch[5] Batch [5]#011Speed: 406.16 samples/sec#011loss=9.686453\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:07 INFO 140518249928512] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481565.778223, \"EndTime\": 1743481567.5552764, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1776.7012119293213, \"count\": 1, \"min\": 1776.7012119293213, \"max\": 1776.7012119293213}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:07 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=359.6359435169165 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:07 INFO 140518249928512] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:07 INFO 140518249928512] #quality_metric: host=algo-1, epoch=5, train loss <loss>=9.657021427154541\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:07 INFO 140518249928512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:07 INFO 140518249928512] Saved checkpoint to \"/opt/ml/model/state_d5310c32-ebc8-4215-aafb-f7ac1fa5abd5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481567.5553439, \"EndTime\": 1743481567.571966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 16.265869140625, \"count\": 1, \"min\": 16.265869140625, \"max\": 16.265869140625}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:07 INFO 140518249928512] Epoch[6] Batch[0] avg_epoch_loss=10.001651\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:07 INFO 140518249928512] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=10.0016508102417\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:08 INFO 140518249928512] Epoch[6] Batch[5] avg_epoch_loss=9.932738\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:08 INFO 140518249928512] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=9.932738304138184\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:08 INFO 140518249928512] Epoch[6] Batch [5]#011Speed: 410.87 samples/sec#011loss=9.932738\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] Epoch[6] Batch[10] avg_epoch_loss=9.802647\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=9.646537590026856\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] Epoch[6] Batch [10]#011Speed: 407.41 samples/sec#011loss=9.646538\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481567.5720236, \"EndTime\": 1743481569.488027, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1915.9491062164307, \"count\": 1, \"min\": 1915.9491062164307, \"max\": 1915.9491062164307}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=341.32793926295335 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] #quality_metric: host=algo-1, epoch=6, train loss <loss>=9.802647070451217\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] Epoch[7] Batch[0] avg_epoch_loss=9.669413\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:09 INFO 140518249928512] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=9.669412612915039\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:10 INFO 140518249928512] Epoch[7] Batch[5] avg_epoch_loss=9.698041\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:10 INFO 140518249928512] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=9.69804080327352\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:10 INFO 140518249928512] Epoch[7] Batch [5]#011Speed: 402.46 samples/sec#011loss=9.698041\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:11 INFO 140518249928512] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481569.4880948, \"EndTime\": 1743481571.2954426, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1806.8766593933105, \"count\": 1, \"min\": 1806.8766593933105, \"max\": 1806.8766593933105}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:11 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=339.23663126228706 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:11 INFO 140518249928512] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:11 INFO 140518249928512] #quality_metric: host=algo-1, epoch=7, train loss <loss>=9.764682483673095\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:11 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:11 INFO 140518249928512] Epoch[8] Batch[0] avg_epoch_loss=9.849948\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:11 INFO 140518249928512] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=9.849947929382324\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:12 INFO 140518249928512] Epoch[8] Batch[5] avg_epoch_loss=9.697241\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:12 INFO 140518249928512] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=9.697240511576334\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:12 INFO 140518249928512] Epoch[8] Batch [5]#011Speed: 413.67 samples/sec#011loss=9.697241\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:13 INFO 140518249928512] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481571.2955341, \"EndTime\": 1743481573.0596938, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1763.8373374938965, \"count\": 1, \"min\": 1763.8373374938965, \"max\": 1763.8373374938965}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:13 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=351.4872368240361 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:13 INFO 140518249928512] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:13 INFO 140518249928512] #quality_metric: host=algo-1, epoch=8, train loss <loss>=9.649001693725586\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:13 INFO 140518249928512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:13 INFO 140518249928512] Saved checkpoint to \"/opt/ml/model/state_708732b8-a1c3-4916-bd26-34fec383b563-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481573.0597618, \"EndTime\": 1743481573.076754, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 16.66116714477539, \"count\": 1, \"min\": 16.66116714477539, \"max\": 16.66116714477539}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:13 INFO 140518249928512] Epoch[9] Batch[0] avg_epoch_loss=9.633618\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:13 INFO 140518249928512] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=9.633618354797363\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] Epoch[9] Batch[5] avg_epoch_loss=9.458153\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=9.458152770996094\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] Epoch[9] Batch [5]#011Speed: 411.38 samples/sec#011loss=9.458153\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] Epoch[9] Batch[10] avg_epoch_loss=9.664094\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=9.911223411560059\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] Epoch[9] Batch [10]#011Speed: 408.25 samples/sec#011loss=9.911223\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481573.0768223, \"EndTime\": 1743481574.9898982, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1913.022518157959, \"count\": 1, \"min\": 1913.022518157959, \"max\": 1913.022518157959}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=337.1474062593935 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] #quality_metric: host=algo-1, epoch=9, train loss <loss>=9.664093971252441\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:14 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:15 INFO 140518249928512] Epoch[10] Batch[0] avg_epoch_loss=9.589751\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:15 INFO 140518249928512] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=9.589751243591309\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:16 INFO 140518249928512] Epoch[10] Batch[5] avg_epoch_loss=9.495836\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:16 INFO 140518249928512] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=9.49583641688029\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:16 INFO 140518249928512] Epoch[10] Batch [5]#011Speed: 410.42 samples/sec#011loss=9.495836\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:16 INFO 140518249928512] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481574.9899578, \"EndTime\": 1743481576.7395113, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1749.1962909698486, \"count\": 1, \"min\": 1749.1962909698486, \"max\": 1749.1962909698486}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:16 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=345.84852524463406 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:16 INFO 140518249928512] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:16 INFO 140518249928512] #quality_metric: host=algo-1, epoch=10, train loss <loss>=9.57915153503418\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:16 INFO 140518249928512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:16 INFO 140518249928512] Saved checkpoint to \"/opt/ml/model/state_3d6d28c3-0679-44a2-8b85-6108b4f867dd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481576.7395809, \"EndTime\": 1743481576.755601, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 15.53487777709961, \"count\": 1, \"min\": 15.53487777709961, \"max\": 15.53487777709961}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:17 INFO 140518249928512] Epoch[11] Batch[0] avg_epoch_loss=9.636140\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:17 INFO 140518249928512] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=9.636139869689941\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:17 INFO 140518249928512] Epoch[11] Batch[5] avg_epoch_loss=9.586153\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:17 INFO 140518249928512] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=9.58615255355835\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:17 INFO 140518249928512] Epoch[11] Batch [5]#011Speed: 409.72 samples/sec#011loss=9.586153\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:18 INFO 140518249928512] Epoch[11] Batch[10] avg_epoch_loss=9.472690\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:18 INFO 140518249928512] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=9.336534118652343\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:18 INFO 140518249928512] Epoch[11] Batch [10]#011Speed: 402.28 samples/sec#011loss=9.336534\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:18 INFO 140518249928512] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481576.755663, \"EndTime\": 1743481578.680573, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1924.851894378662, \"count\": 1, \"min\": 1924.851894378662, \"max\": 1924.851894378662}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:18 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=349.6211371441927 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:18 INFO 140518249928512] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:18 INFO 140518249928512] #quality_metric: host=algo-1, epoch=11, train loss <loss>=9.472689628601074\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:18 INFO 140518249928512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:18 INFO 140518249928512] Saved checkpoint to \"/opt/ml/model/state_e08268ec-db18-4cb6-9476-db414ed84918-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481578.6806338, \"EndTime\": 1743481578.6971965, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 16.18027687072754, \"count\": 1, \"min\": 16.18027687072754, \"max\": 16.18027687072754}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:19 INFO 140518249928512] Epoch[12] Batch[0] avg_epoch_loss=9.697038\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:19 INFO 140518249928512] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=9.697037696838379\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:19 INFO 140518249928512] Epoch[12] Batch[5] avg_epoch_loss=9.456937\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:19 INFO 140518249928512] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=9.456936995188395\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:19 INFO 140518249928512] Epoch[12] Batch [5]#011Speed: 406.17 samples/sec#011loss=9.456937\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] Epoch[12] Batch[10] avg_epoch_loss=9.511825\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=9.577690315246581\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] Epoch[12] Batch [10]#011Speed: 411.46 samples/sec#011loss=9.577690\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481578.6972728, \"EndTime\": 1743481580.6119065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1914.5801067352295, \"count\": 1, \"min\": 1914.5801067352295, \"max\": 1914.5801067352295}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=343.13938917587006 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] #quality_metric: host=algo-1, epoch=12, train loss <loss>=9.511824867942117\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] Epoch[13] Batch[0] avg_epoch_loss=9.301988\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:20 INFO 140518249928512] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=9.301987648010254\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:21 INFO 140518249928512] Epoch[13] Batch[5] avg_epoch_loss=9.449927\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:21 INFO 140518249928512] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=9.449926694234213\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:21 INFO 140518249928512] Epoch[13] Batch [5]#011Speed: 415.15 samples/sec#011loss=9.449927\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:22 INFO 140518249928512] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481580.6119719, \"EndTime\": 1743481582.360252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1747.7939128875732, \"count\": 1, \"min\": 1747.7939128875732, \"max\": 1747.7939128875732}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:22 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=337.54993875474344 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:22 INFO 140518249928512] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:22 INFO 140518249928512] #quality_metric: host=algo-1, epoch=13, train loss <loss>=9.428954029083252\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:22 INFO 140518249928512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:22 INFO 140518249928512] Saved checkpoint to \"/opt/ml/model/state_35a2879f-164c-4e2e-b15e-d9881d08c563-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481582.3603184, \"EndTime\": 1743481582.3768861, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 16.23845100402832, \"count\": 1, \"min\": 16.23845100402832, \"max\": 16.23845100402832}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:22 INFO 140518249928512] Epoch[14] Batch[0] avg_epoch_loss=9.471331\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:22 INFO 140518249928512] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=9.471330642700195\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:23 INFO 140518249928512] Epoch[14] Batch[5] avg_epoch_loss=9.445074\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:23 INFO 140518249928512] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=9.44507360458374\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:23 INFO 140518249928512] Epoch[14] Batch [5]#011Speed: 408.02 samples/sec#011loss=9.445074\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:24 INFO 140518249928512] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481582.3769557, \"EndTime\": 1743481584.137512, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1760.4870796203613, \"count\": 1, \"min\": 1760.4870796203613, \"max\": 1760.4870796203613}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:24 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=343.6331606063253 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:24 INFO 140518249928512] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:24 INFO 140518249928512] #quality_metric: host=algo-1, epoch=14, train loss <loss>=9.47500467300415\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:24 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:24 INFO 140518249928512] Epoch[15] Batch[0] avg_epoch_loss=9.557128\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:24 INFO 140518249928512] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=9.557127952575684\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:25 INFO 140518249928512] Epoch[15] Batch[5] avg_epoch_loss=9.503941\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:25 INFO 140518249928512] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=9.503941218058268\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:25 INFO 140518249928512] Epoch[15] Batch [5]#011Speed: 410.11 samples/sec#011loss=9.503941\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:25 INFO 140518249928512] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481584.1375806, \"EndTime\": 1743481585.8799875, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1741.2943840026855, \"count\": 1, \"min\": 1741.2943840026855, \"max\": 1741.2943840026855}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:25 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=350.29444978099457 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:25 INFO 140518249928512] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:25 INFO 140518249928512] #quality_metric: host=algo-1, epoch=15, train loss <loss>=9.546093368530274\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:25 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:26 INFO 140518249928512] Epoch[16] Batch[0] avg_epoch_loss=9.137597\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:26 INFO 140518249928512] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=9.13759708404541\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:27 INFO 140518249928512] Epoch[16] Batch[5] avg_epoch_loss=9.424464\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:27 INFO 140518249928512] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=9.424464225769043\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:27 INFO 140518249928512] Epoch[16] Batch [5]#011Speed: 404.85 samples/sec#011loss=9.424464\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:27 INFO 140518249928512] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481585.8800538, \"EndTime\": 1743481587.6480846, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1767.5697803497314, \"count\": 1, \"min\": 1767.5697803497314, \"max\": 1767.5697803497314}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:27 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=355.8366728152915 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:27 INFO 140518249928512] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:27 INFO 140518249928512] #quality_metric: host=algo-1, epoch=16, train loss <loss>=9.587670230865479\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:27 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:28 INFO 140518249928512] Epoch[17] Batch[0] avg_epoch_loss=9.927927\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:28 INFO 140518249928512] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=9.927927017211914\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:28 INFO 140518249928512] Epoch[17] Batch[5] avg_epoch_loss=9.631552\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:28 INFO 140518249928512] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=9.63155206044515\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:28 INFO 140518249928512] Epoch[17] Batch [5]#011Speed: 405.66 samples/sec#011loss=9.631552\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:29 INFO 140518249928512] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481587.6481507, \"EndTime\": 1743481589.4221764, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1773.4994888305664, \"count\": 1, \"min\": 1773.4994888305664, \"max\": 1773.4994888305664}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:29 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=350.69766148871986 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:29 INFO 140518249928512] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:29 INFO 140518249928512] #quality_metric: host=algo-1, epoch=17, train loss <loss>=9.513905048370361\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:29 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:29 INFO 140518249928512] Epoch[18] Batch[0] avg_epoch_loss=10.211766\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:29 INFO 140518249928512] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=10.211766242980957\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:30 INFO 140518249928512] Epoch[18] Batch[5] avg_epoch_loss=9.602283\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:30 INFO 140518249928512] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=9.602282524108887\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:30 INFO 140518249928512] Epoch[18] Batch [5]#011Speed: 414.43 samples/sec#011loss=9.602283\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:31 INFO 140518249928512] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481589.422253, \"EndTime\": 1743481591.199922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1777.146816253662, \"count\": 1, \"min\": 1777.146816253662, \"max\": 1777.146816253662}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:31 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=357.29480738703734 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:31 INFO 140518249928512] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:31 INFO 140518249928512] #quality_metric: host=algo-1, epoch=18, train loss <loss>=9.524487209320068\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:31 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:31 INFO 140518249928512] Epoch[19] Batch[0] avg_epoch_loss=9.692830\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:31 INFO 140518249928512] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=9.692830085754395\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] Epoch[19] Batch[5] avg_epoch_loss=9.453471\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=9.453470706939697\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] Epoch[19] Batch [5]#011Speed: 410.84 samples/sec#011loss=9.453471\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481591.1999888, \"EndTime\": 1743481592.949895, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1749.530553817749, \"count\": 1, \"min\": 1749.530553817749, \"max\": 1749.530553817749}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] #throughput_metric: host=algo-1, train throughput=362.9339322221948 records/second\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] #quality_metric: host=algo-1, epoch=19, train loss <loss>=9.482442855834961\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] Final loss: 9.428954029083252 (occurred at epoch 13)\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] #quality_metric: host=algo-1, train final_loss <loss>=9.428954029083252\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 WARNING 140518249928512] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:32 INFO 140518249928512] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481592.9499648, \"EndTime\": 1743481593.0823154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 131.70647621154785, \"count\": 1, \"min\": 131.70647621154785, \"max\": 131.70647621154785}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:33 INFO 140518249928512] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481593.0823824, \"EndTime\": 1743481593.1438725, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 193.30573081970215, \"count\": 1, \"min\": 193.30573081970215, \"max\": 193.30573081970215}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:33 INFO 140518249928512] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:33 INFO 140518249928512] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481593.1439369, \"EndTime\": 1743481593.1535523, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 9.580135345458984, \"count\": 1, \"min\": 9.580135345458984, \"max\": 9.580135345458984}}}\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:33 INFO 140518249928512] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/01/2025 04:26:33 INFO 140518249928512] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1743481593.1536016, \"EndTime\": 1743481593.1633887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 4.51970100402832, \"count\": 1, \"min\": 4.51970100402832, \"max\": 4.51970100402832}, \"totaltime\": {\"sum\": 38149.9924659729, \"count\": 1, \"min\": 38149.9924659729, \"max\": 38149.9924659729}}}\u001b[0m\n",
      "\n",
      "2025-04-01 04:26:52 Uploading - Uploading generated training model\n",
      "2025-04-01 04:26:52 Completed - Training job completed\n",
      "Training seconds: 250\n",
      "Billable seconds: 250\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "hyperparameters = {\n",
    "    \"time_freq\": \"D\",\n",
    "    \"epochs\": \"20\",\n",
    "    \"early_stopping_patience\": \"10\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "    \"num_cells\": \"40\",\n",
    "    \"num_layers\": \"3\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"context_length\": \"30\",            \n",
    "    \"prediction_length\": \"14\" \n",
    "}\n",
    "\n",
    "estimator = Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    sagemaker_session=session,\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "\n",
    "estimator.fit({'train': s3_path})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
